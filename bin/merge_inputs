#!/usr/bin/env python

# Merges inputs csv file into one

import argparse
import logging
import os
import pandas as pd

from common.configuration import ConfigurationHandler
from common.workspace import WorkspaceHandler

logger = logging.getLogger('pyccflex')
logger.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
logger.addHandler(ch)

if __name__ == '__main__':

    logger.info("\n#### Running: {}".format(__file__))

    # Parse input parameters
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_files', nargs='+', type=str,
                        help="The list of input files to merge", required=True)
    parser.add_argument("--output_file", help="The name of the output file",
                        default=False, type=str)
    parser.add_argument("--locations_config", help="Path to locations configuration file",
                        type=str, required=False, default="./locations.json")
    parser.add_argument("--files_format_config", help="Path to files format configuration file",
                        type=str, required=False, default="./files_format.json")
    parser.add_argument("--classes_config", help="Path to classes configuration file",
                        type=str, required=False, default="./classes.json")
    parser.add_argument("--classifiers_options", help="Path to classifiers options file",
                        type=str, required=False, default="./classifiers_options.json")
    parser.add_argument("--add_decision_class", help="Shall the decision class be added to output?",
                        default=False, action='store_true')
    parser.add_argument("--add_contents", help="Shall the content of the line be added to output?",
                        default=False, action='store_true')

    args = vars(parser.parse_args())
    logger.info("Run parameters: {}".format(str(args)))

    locations_file_path = args['locations_config']
    files_format_file_path = args['files_format_config']
    classes_file_path = args['classes_config']
    classifiers_options_file_path = args['classifiers_options']

    input_files = args['input_files']
    if len(input_files) < 2:
        logger.error("At least two input files need to be provided")
        exit(1)

    output_file = args['output_file']

    try:
        locations_config = ConfigurationHandler(locations_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(locations_file_path))
        exit(1)

    try:
        files_format_config = ConfigurationHandler(files_format_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(files_format_file_path))
        exit(1)

    try:
        classifiers_options_config = ConfigurationHandler(classifiers_options_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(classifiers_options_file_path))
        exit(1)

    try:
        classes_config = ConfigurationHandler(classes_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(classes_file_path))
        exit(1)
    decision_classes = classes_config.get("classes", {})

    csv_separator = files_format_config.get("csv_sep", ",")

    workspace_dir_conf = locations_config.get('workspace_dir', None)
    workspace_dir_path = workspace_dir_conf.get("path", "")
    workspace_dir = WorkspaceHandler(workspace_dir_path)

    add_decision_class = args['add_decision_class']
    add_contents = args['add_contents']

    logger.info(">>> Starting to merge the input csv files...")

    output_file_path = workspace_dir.get_processing_file_path(output_file)

    decision_class_name_column = None
    decision_class_value_column = None
    contents_column = None
    merged_df = None
    for input_file in input_files:
        input_file_path = workspace_dir.get_processing_file_path(input_file)
        input_df = pd.read_csv(input_file_path, sep=csv_separator, encoding="utf-8")

        logger.info(">>> Merging the file {}".format(input_file))

        columns = list(input_df.columns)
        if decision_class_name_column is None and 'class_value' in columns:
            decision_class_name_column = input_df['class_name']
            decision_class_value_column = input_df['class_value']

        if contents_column is None and 'contents' in columns:
            contents_column = input_df['contents']

        collumns_to_drop = []
        if 'class_value' in columns:
            collumns_to_drop.append('class_value')
            collumns_to_drop.append('class_name')
        if 'contents' in columns:
            collumns_to_drop.append('contents')
        input_df.drop(collumns_to_drop, inplace=True, axis=1)

        if merged_df is None:
            merged_df = input_df
        else:
            input_df.drop(['id'], inplace=True, axis=1)
            merged_df = pd.concat([merged_df, input_df], axis=1)

    if add_decision_class and decision_class_name_column is not None:
        merged_df['class_name'] = decision_class_name_column
        merged_df['class_value'] = decision_class_value_column

    if add_contents and contents_column is not None:
        merged_df['contents'] = contents_column

    logger.info(">>>> Saving the merged file {}".format(output_file))
    merged_df.to_csv(output_file_path, sep=csv_separator, index=False, encoding="utf-8")


