#!/usr/bin/env python

# Reading input csv file with features, performs feature selection and storres the resulting features file

import argparse
import csv
import logging
import warnings
import pandas as pd
from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SelectFpr
import gc
import numpy as np

from common.configuration import ConfigurationHandler
from common.workspace import WorkspaceHandler

logger = logging.getLogger('pyccflex')
logger.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
logger.addHandler(ch)

if __name__ == '__main__':

    logger.info("\n#### Running: {}".format(__file__))

    # Parse input parameters
    parser = argparse.ArgumentParser()
    parser.add_argument("train_file",
                        help="Path to train csv file", type=str)
    parser.add_argument("selected_features_file",
                        help="Path to classify csv file", type=str)
    parser.add_argument('--feature_selector', type=str, required=True)
    parser.add_argument("--locations_config", help="Path to locations configuration file",
                        type=str, required=False, default="./locations.json")
    parser.add_argument("--files_format_config", help="Path to files format configuration file",
                        type=str, required=False, default="./files_format.json")
    parser.add_argument("--classifiers_options", help="Path to classifiers options file",
                        type=str, required=False, default="./classifiers_options.json")
    parser.add_argument("--feature_selectors_options", help="Path to feature selectors options file",
                        type=str, required=False, default="./feature_selectors_options.json")
    parser.add_argument("--chunk_size", help="Number of lines to process in a batch",
                        type=int, required=False, default=10 ** 5)

    args = vars(parser.parse_args())
    logger.info("Run parameters: {}".format(str(args)))

    locations_file_path = args['locations_config']
    files_format_file_path = args['files_format_config']
    classifiers_options_file_path = args['classifiers_options']
    feature_selectors_options_file_path = args['feature_selectors_options']

    train_file = args['train_file']
    selected_features_file = args['selected_features_file']
    feature_selector = args['feature_selector']
    chunk_size = args['chunk_size']

    try:
        locations_config = ConfigurationHandler(locations_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(locations_file_path))
        exit(1)

    try:
        files_format_config = ConfigurationHandler(files_format_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(files_format_file_path))
        exit(1)

    try:
        classifiers_options_config = ConfigurationHandler(classifiers_options_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(classifiers_options_file_path))
        exit(1)

    try:
        feature_selectors_options_config = ConfigurationHandler(feature_selectors_options_file_path)
    except Exception as e:
        logger.error("Couldn't load configuration file {}".format(feature_selectors_options_file_path))
        exit(1)

    csv_separator = files_format_config.get("csv_sep", ",")

    workspace_dir_conf = locations_config.get('workspace_dir', None)
    workspace_dir_path = workspace_dir_conf.get("path", "")
    workspace_dir = WorkspaceHandler(workspace_dir_path)

    logger.info(">>> Loading training file {}".format(train_file))
    input_train_file_path = workspace_dir.get_processing_file_path(train_file)
    input_train_df = pd.read_csv(input_train_file_path, sep=csv_separator, encoding="utf-8")
    output_train_file_path = workspace_dir.get_processing_file_path(selected_features_file)

    # temporary remove class and contents
    decision_class_name_column_train = None
    decision_class_value_column_train = None
    contents_column_train = None
    ids_column_train = input_train_df['id']
    columns_train = list(input_train_df.columns)
    columns_to_drop_train = ['id']
    if 'class_value' in columns_train:
        decision_class_name_column_train = input_train_df['class_name']
        decision_class_value_column_train = input_train_df['class_value']
        columns_to_drop_train.append('class_value')
        columns_to_drop_train.append('class_name')
    if 'contents' in columns_train:
        contents_column_train = input_train_df['contents']
        columns_to_drop_train.append('contents')
    input_train_df.drop(columns_to_drop_train, inplace=True, axis=1)

    train_x = input_train_df
    train_y = decision_class_value_column_train

    selector_options = feature_selectors_options_config.get(feature_selector, {})

    if feature_selector == "VarianceThreshold":
        logger.info(">>> {}: determining features".format(feature_selector))
        selector = VarianceThreshold(**selector_options)
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=FutureWarning)
            selector.fit(train_x, train_y)
            selected_features = train_x.columns[selector.get_support()]
            selected_features = np.array(selected_features)

    if feature_selector == "SelectPercentile":
        logger.info(">>> {}: determining features".format(feature_selector))
        selector = SelectPercentile(**selector_options)
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=FutureWarning)
            selector.fit(train_x, train_y)
            selected_features = train_x.columns[selector.get_support()]
            selected_features = np.array(selected_features)

    if feature_selector == "SelectFpr":
        logger.info(">>> {}: determining features".format(feature_selector))
        selector = SelectFpr(**selector_options)
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=FutureWarning)
            selector.fit(train_x, train_y)
            selected_features = train_x.columns[selector.get_support()]
            selected_features = np.array(selected_features)

    logger.info(">>> Selected {} out of {} features...".format(selected_features.shape[0], train_x.shape[1]))
    selected_features_df = pd.DataFrame(selected_features, columns=["features"])

    logger.info(">>> Saving output to the file {}".format(output_train_file_path))
    selected_features_df.to_csv(output_train_file_path, sep=csv_separator, index=False, encoding="utf-8", header=True,
                                quoting=csv.QUOTE_NONNUMERIC)
